/* vm.c: Generic interface for virtual memory objects. */

#include "threads/malloc.h"
#include "vm/vm.h"
#include "vm/inspect.h"
#include "threads/pte.h"
#include "vm/file.h"
#include "userprog/process.h"
#include <stdio.h>

#include <string.h> // memcpy
#include "threads/mmu.h" // pml4 set

// frame table: victim ì„ ì²­ì„ ìœ„í•œ ìžë£Œêµ¬ì¡°
struct list frame_table;

/* Initializes the virtual memory subsystem by invoking each subsystem's
 * intialize codes. */
void
vm_init (void) {
	vm_anon_init ();
	vm_file_init ();
#ifdef EFILESYS  /* For project 4 */
	pagecache_init ();
#endif
	register_inspect_intr ();
	/* DO NOT MODIFY UPPER LINES. */
	/* TODO: Your code goes here. */
  list_init(&frame_table);
}

/* Get the type of the page. This function is useful if you want to know the
 * type of the page after it will be initialized.
 * This function is fully implemented now. */
enum vm_type
page_get_type (struct page *page) {
	int ty = VM_TYPE (page->operations->type);
	switch (ty) {
		case VM_UNINIT:
			return VM_TYPE (page->uninit.type);
		default:
			return ty;
	}
}

/* Helpers */
static struct frame *vm_get_victim (void);
static bool vm_do_claim_page (struct page *page);
static struct frame *vm_evict_frame (void);
static uint64_t page_hash(const struct hash_elem *p_, void *aux UNUSED);

/* Create the pending page object with initializer. If you want to create a
 * page, do not create it directly and make it through this function or
 * `vm_alloc_page`. */
// lazy load ìƒíƒœë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ìš©.
bool vm_alloc_page_with_initializer(enum vm_type type, void *upage,
                                    bool writable, vm_initializer *init,
                                    void *aux) {
  struct supplemental_page_table *spt = &thread_current()->spt;
  struct page *page = NULL;
  void *upage_entry = pg_round_down(upage);
  void *initializer = NULL;

  ASSERT (VM_TYPE(type) != VM_UNINIT)
  ASSERT (is_user_vaddr (upage));

  /* Check wheter the upage is already occupied or not. */
  if ((page = spt_find_page(spt, upage_entry)) == NULL) {
    /* TODO: Create the struct page, fetch the initialier according to the VM
     * type,
     * TODO: and then create "uninit" page struct by calling uninit_new. You
     * TODO: should modify the field after calling the uninit_new. */
    page = (struct page *)calloc(1, sizeof(struct page));
    if (page == NULL) {
      return false;
    }

    switch (type) {
    case VM_ANON:
      initializer = anon_initializer;
      break;
    case VM_FILE:
      initializer = file_backed_initializer;
      break;
    default:
      NOT_REACHED();
    }

    ASSERT (initializer != NULL);
    uninit_new(page, upage_entry, init, type, aux, initializer);

    page->writable = writable;

    /* Insert the page into the spt. */
    spt_insert_page(spt, page);
  }

  // sptì— pageê°€ ì¡´ìž¬í•˜ë©´ trueë¥¼ ë°˜í™˜í•œë‹¤.
  return true;
}

/** 
 * @brief Find VA from spt and return page. On error, return NULL. 
*/
struct page *
spt_find_page (struct supplemental_page_table *spt UNUSED, void *va UNUSED) {
  ASSERT (pg_ofs(va) == 0);
  
	struct page *page = page_lookup(spt, va);
	return page;
}

/** 
 * @brief Insert PAGE into spt with validation. 
 */
bool
spt_insert_page (struct supplemental_page_table *spt UNUSED,
		struct page *page UNUSED) {
	int succ = false;

	if (page) { // TODO - page validation
		succ = true;
		hash_insert(&spt->page_map, &page->hash_elem);
	}

	return succ;
}

/**
 * @brief sptë¡œë¶€í„° pageë¥¼ í•´ì œí•œë‹¤.
 */
void
spt_remove_page (struct supplemental_page_table *spt, struct page *page) {
	ASSERT(hash_delete(&spt->page_map, &page->hash_elem));
	vm_dealloc_page (page);
}

static bool frame_less (struct list_elem *a, struct list_elem *b) {
  struct frame *frame_a = list_entry(a, struct frame, elem);
  struct frame *frame_b = list_entry(b, struct frame, elem);

  return frame_a->ref_cnt < frame_b->ref_cnt;
}

/* Get the struct frame, that will be evicted. */
static struct frame *
vm_get_victim (void) {
	struct frame *victim = NULL;
  struct list_elem *e = NULL;
  if (list_empty(&frame_table)) {
    return NULL; // TODO kernel panic?
  }

  // // policy: FIFO
  // e = list_pop_front(&frame_table);
  // list_push_back(&frame_table, e);

  // policy: ref_cntê°€ ê°€ìž¥ ìž‘ì€ frameì„ victimìœ¼ë¡œ ì„ ì •
  e = list_min(&frame_table, frame_less, NULL);
  list_remove(e);
  list_push_back(&frame_table, e);

  victim = list_entry(e, struct frame, elem);

  ASSERT (victim->ref_cnt <= 1);

	return victim;
}

/* Evict one page and return the corresponding frame.
 * Return NULL on error.*/
static struct frame *
vm_evict_frame (void) {
	struct frame *victim UNUSED = vm_get_victim ();
  if (victim == NULL) {
    return NULL; // TODO kernel panic?
  }
  
  if (list_empty (&victim->page_list)) {
    return victim;
  }

  // pageì™€ frameì„ ë¶„ë¦¬
  while (!list_empty (&victim->page_list)) {
    // swap out page element and unlink it
    struct list_elem *e = list_pop_front (&victim->page_list);
    struct page *page = list_entry(e, struct page, frame_elem);
    
    swap_out(page);
    pml4_clear_page(thread_current()->pml4, page->va);
    victim->ref_cnt -= 1;
    page->frame = NULL;
    list_remove(&page->frame_elem);
  }

  ASSERT(victim->ref_cnt == 0 && list_empty(&victim->page_list));
  ASSERT(victim != NULL);
	return victim;
}

/* palloc() and get frame. If there is no available page, evict the page
 * and return it. This always return valid address. That is, if the user pool
 * memory is full, this function evicts the frame to get the available memory
 * space.*/
static struct frame *
vm_get_frame (void) {
  // ë°˜í™˜ëœ ì£¼ì†Œê°€ 0ìœ¼ë¡œ ì´ˆê¸°í™” ë˜ì–´ìžˆë‹¤ëŠ” ë³´ìž¥ì€ ì—†ë‹¤.
	void *kva = palloc_get_page(PAL_USER); // kva - kernel virtual address
	if (kva == NULL) {
		// ë¹ˆ íŽ˜ì´ì§€ê°€ ì—†ìœ¼ë©´ evict ìˆ˜í–‰
		return vm_evict_frame();
	}
  
  struct frame *frame = malloc(sizeof(struct frame));
  frame->kva = kva;
  list_init(&frame->page_list);
  frame->ref_cnt = 0;

  list_push_back(&frame_table, &frame->elem); // ìƒì„±í•œ frame ê´€ë¦¬

	ASSERT (frame != NULL);
	ASSERT (list_empty(&frame->page_list));
	return frame;
}

/* Growing the stack. */
static void
vm_stack_growth (void *addr UNUSED) {
	// TODO - stack growth
  if (!vm_alloc_page_with_initializer(VM_ANON, pg_round_down(addr), true, pml4_setter, NULL)) {
    PANIC ("VM: fail to allocate an struct page in stack growth.\n");
  }

  vm_claim_page(addr);
}

/* Handle the fault on write_protected page */
static bool
vm_handle_wp (struct page *page UNUSED) {
  if (page->writable == false) {
    return false;
  }

  if (page->frame->ref_cnt <= 1) {
    // referenceê°€ í•˜ë‚˜ (ë‚˜ ìžì‹ )ì´ë©´ ê·¸ëŒ€ë¡œ ì¨ë„ ëœë‹¤.
    pml4_set_page(thread_current()->pml4, page->va, page->frame->kva, page->writable); // cow
    return true;
  }

  struct frame *dup_frame = vm_get_frame();
  memcpy(dup_frame->kva, page->frame->kva, PGSIZE);

  // unlink frame
  page->frame->ref_cnt -= 1; 
  list_remove(&page->frame_elem);

  // link page to frame
  page->frame = dup_frame;
  list_push_back(&dup_frame->page_list, &page->frame_elem); // link page to frame
  dup_frame->ref_cnt += 1;

  pml4_set_page(thread_current()->pml4, page->va, dup_frame->kva, page->writable); // cow

  return true;
}

/* Return true on success */
bool vm_try_handle_fault(struct intr_frame *f UNUSED, void *addr UNUSED,
                         bool user UNUSED, bool write UNUSED,
                         bool not_present UNUSED) {
  struct supplemental_page_table *spt = &thread_current()->spt;
  struct page *page = NULL;
	void *upage_entry = pg_round_down(addr);

  /* Validate the fault */
  if (is_user_vaddr(addr) == false) { // if page's type is uninit, BOOM
    return false;
  }
  // printf("[*] ðŸ’¥ fault_address: %p\n", addr);

  if ((page = spt_find_page(spt, upage_entry)) != NULL) {
    if (page->frame == NULL) {
      return vm_do_claim_page(page);
    } else {
      ASSERT(write == true);
      return vm_handle_wp(page);
    }
  } else {
  	/* ì—¬ê¸°ì„œë¶€í„°ëŠ” pageê°€ ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” ìš”ì²­ì— ëŒ€í•´ ì²˜ë¦¬ ìˆ˜í–‰ - ëª…ì‹œì ì¸ í• ë‹¹ ìš”ì²­ì´ ì—†ì—ˆìŒ */
    if ((uint64_t)f->rsp <= (uint64_t)addr && (uint64_t)addr < USER_STACK) {
      // stack growth with legitimate stack pointer
      // `CALL` ëª…ë ¹ê³¼ í•¨ê»˜ rspê°€ ì¦ê°€í•œ ìƒíƒœë¡œ page faultê°€ ë°œìƒí•´ì•¼ë§Œ OK
      vm_stack_growth(upage_entry);
      struct page *_p = spt_find_page(spt, upage_entry);
      if (_p != NULL) {
        // pml4_clear_page(thread_current()->pml4, _p->va);
        pml4_set_page(thread_current()->pml4, _p->va, _p->frame->kva, false); // cow
      } else {
        return false;
      }

      return true;
    }
  }

  return false;
  // return vm_do_claim_page (page);
}

/* Free the page.
 * DO NOT MODIFY THIS FUNCTION. */
void
vm_dealloc_page (struct page *page) {
	destroy (page);
	free (page);
}

/* Claim the page that allocate on VA. */
// íŽ˜ì´ì§€ë§Œ ì¶”ê°€ë¡œ ìƒì„±í•˜ê³ , frameì€ ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤.
// íŽ˜ì´ì§€ê°€ ì¡´ìž¬í•˜ì§€ ì•Šì§€ë§Œ ì¤˜ì•¼í•˜ëŠ” ê²½ìš° ì‚¬ìš© ex) stack growth
// claimì„ ê±´ë‹¤. ë‚´êº¼ì•¼! ì´ ì£¼ì†Œ ë‚´êº¼ì•¼ ì¤˜! sptì— ë‚´ ì£¼ì†Œ(íŽ˜ì´ì§€)ë¥¼ ì¶”ê°€í•´ì¤˜!
bool
vm_claim_page (void *va UNUSED) {
	ASSERT (va != NULL);
  ASSERT (pg_ofs(va) == 0);

  if (vm_alloc_page_with_initializer(VM_ANON, va, true, pml4_setter, NULL)) {
    struct page *page = page_lookup(&thread_current()->spt, va);
	  return vm_do_claim_page (page);
  }
  
  return false;
}

/** 
 * Claim the PAGE and set up the mmu. 
 * pageë¥¼ ì „ë‹¬ë°›ì•„ frameì„ ìƒì„±í•˜ê³  ë§¤í•‘í•œë‹¤.
 * íŽ˜ì´ì§€ê°€ ì¡´ìž¬í•˜ë©´ frameì„ í• ë‹¹í•´ì¤„ ëª©ì ìœ¼ë¡œ ì‚¬ìš©, claimì„ ì²˜ë¦¬í•´ì¤€ë‹¤.
 * ì•„ì´êµ¬ ê³ ê°ë‹˜ ê³ ìƒì´ ë§Žìœ¼ì…¨ê² ì–´ìš” ^^ ì²˜ë¦¬í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
 * pml4 - kva ì—°ê²° ìž‘ì—…ì€ operation ì—ì„œ í•œë‹¤.
 */
static bool
vm_do_claim_page (struct page *page) {
	struct frame *frame = vm_get_frame ();
  ASSERT (frame != NULL);

	/* Set links */
	// frame->page = page;
  list_push_back(&frame->page_list, &page->frame_elem);
	page->frame = frame;
  frame->ref_cnt += 1;

  // anonymous ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤˜ì•¼ í•œë‹¤.
  if (page_get_type(page) == VM_ANON) {
    memset(frame->kva, 0, PGSIZE);
  }

  bool success = swap_in (page, frame->kva);
  if (success) {
    pml4_set_page(thread_current()->pml4, page->va, frame->kva, false); // cow
  }

	return success;
}

static bool page_less(const struct hash_elem *a, const struct hash_elem *b, void *aux UNUSED) {
	struct page *page_a = hash_entry(a, struct page, hash_elem);
	struct page *page_b = hash_entry(b, struct page, hash_elem);

	return page_a->va < page_b->va;
}

static uint64_t page_hash(const struct hash_elem *p_, void *aux UNUSED) {
	const struct page *p = hash_entry(p_, struct page, hash_elem);
	return hash_bytes(&p->va, sizeof p->va);
}

/* Initialize new supplemental page table */
void
supplemental_page_table_init (struct supplemental_page_table *spt UNUSED) {
	// hash init
	hash_init(&spt->page_map, page_hash, page_less, NULL);

	// TODO ì¶”ê°€ì ì¸ ìž‘ì—… í•„ìš”
}

/**
 * @brief Get the size of aux object
 * @note ëª¨ë“  aux ì¸ìž ì „ë‹¬ êµ¬ì¡°ì²´ëŠ” ì²«ë²ˆì§¸ í•„ë“œë¡œ sizeë¥¼ ê°€ì§€ê³  ìžˆë‹¤.
 * @param aux 
 * @return uint64_t 
 */
static uint64_t get_size_of_aux(void *aux) {
  return *(uint64_t *)aux;
}

/* Copy supplemental page table from src to dst */
bool supplemental_page_table_copy(struct supplemental_page_table *dst UNUSED,
                                  struct supplemental_page_table *src UNUSED) {
  struct hash_iterator i;
  struct page *p, *dup_p;

  // í˜„ìž¬ child thread ì‹¤í–‰ì¤‘ì¸ ìƒíƒœ
  hash_first(&i, &src->page_map);
  while (hash_next(&i)) {
    p = hash_entry(hash_cur(&i), struct page, hash_elem);
    dup_p = (struct page *)calloc(1, sizeof(struct page));
    memcpy(dup_p, p, sizeof(struct page));

    if (p->operations->type == VM_UNINIT) {
      // ë¶€ëª¨ íŽ˜ì´ì§€ì— frameì´ í• ë‹¹ë˜ì–´ ìžˆì§€ ì•Šìœ¼ë©´ (fault ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìœ¼ë©´) auxë¥¼ ë³µì‚¬
      uint64_t aux_size = get_size_of_aux(p->uninit.aux);
      dup_p->uninit.aux = calloc(1, aux_size);

      // TODO file duplicate í•´ì„œ ë„˜ê²¨ì£¼ìž
      
      memcpy(dup_p->uninit.aux, p->uninit.aux, aux_size);
    } else {
      // ë¶€ëª¨ íŽ˜ì´ì§€ì— frameì´ ì´ë¯¸ í• ë‹¹ë˜ì–´ ìžˆìœ¼ë©´ (fault ê°€ ì´ë¯¸ ë°œìƒí–ˆìœ¼ë©´) reference countë§Œ ì¦ê°€
      dup_p->frame = p->frame;
      dup_p->frame->ref_cnt += 1;

      // ì „ë¶€ read onlyë¡œ ì„¤ì •í•˜ê³ , ë‚˜ì¤‘ì— writeê°€ ë°œìƒí•˜ë©´ faultê°€ ë°œìƒí•˜ë„ë¡ í•œë‹¤.
      pml4_set_page(thread_current()->pml4, p->va, dup_p->frame->kva, false); // cow
    }

    hash_insert(&dst->page_map, &dup_p->hash_elem);
  }

  ASSERT(hash_size(&dst->page_map) == hash_size(&src->page_map));
  return true;
}

static void vm_dealloc_page_each(struct hash_elem *e, void *aux UNUSED) {
  struct page *p = hash_entry(e, struct page, hash_elem);
  // destoryê°€ í˜¸ì¶œë˜ì–´ë„ frameì„ free ì‹œí‚¤ì§€ ì•Šìœ¼ë¯€ë¡œ ëª¨ë“  íŽ˜ì´ì§€ì— ëŒ€í•´ dealloc page ìˆ˜í–‰ ê°€ëŠ¥
  vm_dealloc_page(p); 
}

/* Free the resource hold by the supplemental page table */
void
supplemental_page_table_kill (struct supplemental_page_table *spt UNUSED) {
	/* TODO: Destroy all the supplemental_page_table hold by thread and
	 * TODO: writeback all the modified contents to the storage. */
  hash_clear(&spt->page_map, vm_dealloc_page_each);
  ASSERT (hash_size(&spt->page_map) == 0);
}

/** 
 * @brief Returns the page containing the given virtual address, or a null pointer if no such page exists. 
 */
struct page *
page_lookup (struct supplemental_page_table *spt, const void *address) {
  struct page p;
  struct hash_elem *e;

	p.va = (void *)address;
  e = hash_find(&spt->page_map, &p.hash_elem);
  return e != NULL ? hash_entry (e, struct page, hash_elem) : NULL;
}
